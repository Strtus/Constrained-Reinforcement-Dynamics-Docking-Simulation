#!/usr/bin/env python3
"""
åƒå¸†å«æ˜Ÿäº¤ä¼šå¯¹æ¥è®­ç»ƒ - ç®€åŒ–ç‰ˆæœ¬
ä¸ä¾èµ–å¤æ‚çš„å¤–éƒ¨åº“ï¼Œä½¿ç”¨åŸºç¡€Pythonåº“
"""

import math
import random
import os
import time
import sys
import json
import numpy as np
import matplotlib.pyplot as plt
class SimpleQianfanTrainer:
    """ç®€åŒ–çš„åƒå¸†å«æ˜Ÿè®­ç»ƒå™¨"""
    def __init__(self):
        self.spacecraft_mass = 150.0  # kg
        self.orbit_altitude = 500000  # m (500km)
        self.max_thrust = 0.5  # N per thruster
        self.num_thrusters = 8
        self.orbital_period = 5676  # ç§’
        self.orbital_velocity = 7612  # m/s
        self.episodes = 12000  # æ•´å¤œè®­ç»ƒ
        self.max_steps_per_episode = 3000
        self.output_dir = "training_outputs"
        os.makedirs(self.output_dir, exist_ok=True)
        self.best_distance = float('inf')
        self.distance_improvement_bonus = 0
        self.curriculum_stage = 1
        self.use_nn_controller = False
        self.nn_controller = None
    def orbital_dynamics(self, position, velocity, thrust_vector):
        x, y, z = position
        vx, vy, vz = velocity
        fx, fy, fz = thrust_vector
        n = 2 * math.pi / self.orbital_period
        ax = 3 * n**2 * x + 2 * n * vy + fx / self.spacecraft_mass
        ay = -2 * n * vx + fy / self.spacecraft_mass
        az = -n**2 * z + fz / self.spacecraft_mass
        return [ax, ay, az]
    def save_training_progress(self, progress_data):
        import json
        progress_file = os.path.join(self.output_dir, "training_progress.json")
        if os.path.exists(progress_file):
            with open(progress_file, 'r', encoding='utf-8') as f:
                all_progress = json.load(f)
        else:
            all_progress = []
        all_progress.append(progress_data)
        with open(progress_file, 'w', encoding='utf-8') as f:
            json.dump(all_progress, f, indent=2, ensure_ascii=False)
        print(f"   è®­ç»ƒè¿›åº¦å·²ä¿å­˜åˆ°: {progress_file}")
    # ...existing code...
    
    def simulate_docking_scenario(self):
        """æ¨¡æ‹Ÿå¯¹æ¥åœºæ™¯ - ä¼˜åŒ–ç‰ˆæœ¬"""
        # éšæœºåˆå§‹ä½ç½®å’Œé€Ÿåº¦
        position = [
            random.uniform(50.0, 200.0),    # 50-200mè·ç¦»
            random.uniform(-50.0, 50.0),    # æ¨ªå‘åå·®
            random.uniform(-30.0, 30.0)     # æ³•å‘åå·®
        ]
        velocity = [
            random.uniform(-0.2, 0.2),      # å¾„å‘é€Ÿåº¦
            random.uniform(-0.1, 0.1),      # æ¨ªå‘é€Ÿåº¦  
            random.uniform(-0.1, 0.1)       # æ³•å‘é€Ÿåº¦
        ]
        
        target_position = [0.0, 0.0, 0.0]  # ç›®æ ‡ä½ç½®
        initial_distance = math.sqrt(sum(p**2 for p in position))
        self.best_distance = initial_distance  # é‡ç½®æœ€ä½³è·ç¦»
        
        print(f"\nå¼€å§‹å¯¹æ¥ä»»åŠ¡")
        print(f"   åˆå§‹è·ç¦»: {initial_distance:.1f} m")
        
        dt = 1.0  # æ—¶é—´æ­¥é•¿ 1ç§’
        reward_history = []  # è®°å½•å¥–åŠ±å†å²
        
        for step in range(self.max_steps_per_episode):
            # è®¡ç®—è·ç¦»å’Œé€Ÿåº¦
            distance = math.sqrt(sum((p - tp)**2 for p, tp in zip(position, target_position)))
            speed = math.sqrt(sum(v**2 for v in velocity))
            # å¥–åŠ±å¡‘å½¢ï¼šè®°å½•è·ç¦»æ”¹å–„
            if distance < self.best_distance:
                self.distance_improvement_bonus += (self.best_distance - distance) * 10
                self.best_distance = distance
            # è®¡ç®—å³æ—¶å¥–åŠ±
            instant_reward = -distance - 10*speed  # è·ç¦»å’Œé€Ÿåº¦æƒ©ç½š
            if distance < 10.0:
                instant_reward += 50  # æ¥è¿‘å¥–åŠ±
            if distance < 5.0:
                instant_reward += 100  # è¿‘è·ç¦»å¥–åŠ±
            reward_history.append(instant_reward)
            if distance < 2.0 and speed < 0.2:  # æ”¾å®½æˆåŠŸå¯¹æ¥æ¡ä»¶
                total_reward = sum(reward_history) + self.distance_improvement_bonus + 1000  # æˆåŠŸå¥–åŠ±
                print(f"ç¬¬{step}æ­¥æˆåŠŸå¯¹æ¥ï¼è·ç¦»: {distance:.2f} m, é€Ÿåº¦: {speed:.3f} m/s")
                print(f"   æ€»å¥–åŠ±: {total_reward:.1f}, è·ç¦»æ”¹å–„å¥–åŠ±: {self.distance_improvement_bonus:.1f}")
                return True, step
            if distance > 1000.0:  # è¶…å‡ºèŒƒå›´
                print(f"ç¬¬{step}æ­¥è¶…å‡ºèŒƒå›´ï¼Œä»»åŠ¡å¤±è´¥")
                return False, step
            # è‡ªé€‚åº”PDæ§åˆ¶ç­–ç•¥ï¼ˆåŸºäºè·ç¦»è°ƒæ•´å¢ç›Šï¼‰
            if distance > 50:
                kp, kd = 0.01, 0.3
            elif distance > 10:
                kp, kd = 0.02, 0.5
            elif distance > 5:
                kp, kd = 0.03, 0.7
            else:
                kp, kd = 0.05, 1.0
            thrust_vector = []
            for i in range(3):
                position_error = position[i] - target_position[i]
                thrust_i = -kp * position_error - kd * velocity[i]
                thrust_vector.append(thrust_i)
            max_total_thrust = self.num_thrusters * self.max_thrust
            thrust_magnitude = math.sqrt(sum(f**2 for f in thrust_vector))
            if thrust_magnitude > max_total_thrust:
                scale = max_total_thrust / thrust_magnitude
                thrust_vector = [f * scale for f in thrust_vector]
            acceleration = self.orbital_dynamics(position, velocity, thrust_vector)
            for i in range(3):
                velocity[i] += acceleration[i] * dt
                position[i] += velocity[i] * dt
            if step % 200 == 0:
                improvement = f", æ”¹å–„: {self.distance_improvement_bonus:.1f}" if self.distance_improvement_bonus > 0 else ""
                print(f"   ç¬¬{step}æ­¥: è·ç¦»={distance:.1f}m, é€Ÿåº¦={speed:.3f}m/s{improvement}")
        final_reward = sum(reward_history) + self.distance_improvement_bonus - 500  # è¶…æ—¶æƒ©ç½š
        print(f"è¾¾åˆ°æœ€å¤§æ­¥æ•°ï¼Œä»»åŠ¡è¶…æ—¶ã€‚æœ€ç»ˆå¥–åŠ±: {final_reward:.1f}")
        return False, self.max_steps_per_episode
    
    def train(self):
        """æ‰§è¡Œè®­ç»ƒä¸»å¾ªç¯"""
        print(f"\nå¼€å§‹åƒå¸†å«æ˜Ÿäº¤ä¼šå¯¹æ¥è®­ç»ƒ")
        print(f"   æ€»è®­ç»ƒè½®æ•°: {self.episodes}")
        successful_episodes = 0
        total_steps = 0
        start_time = time.time()
        for episode in range(self.episodes):
            # è¯¾ç¨‹å­¦ä¹ é˜¶æ®µåˆ’åˆ†
            if episode < int(self.episodes * 0.3):
                self.curriculum_stage = 1
            elif episode < int(self.episodes * 0.7):
                self.curriculum_stage = 2
            else:
                self.curriculum_stage = 3
            print(f"\nEpisode {episode + 1}/{self.episodes} (é˜¶æ®µ{self.curriculum_stage})")
            success, steps = self.simulate_docking_scenario()
            total_steps += steps
            if success:
                successful_episodes += 1
            success_rate = successful_episodes / (episode + 1) * 100
            avg_steps = total_steps / (episode + 1)
            print(f"   æˆåŠŸç‡: {success_rate:.1f}% ({successful_episodes}/{episode + 1})")
            print(f"   å¹³å‡æ­¥æ•°: {avg_steps:.1f}")
            if (episode + 1) % 100 == 0:
                elapsed_time = time.time() - start_time
                print(f"\né˜¶æ®µæ€»ç»“ (å‰{episode + 1}è½®):")
                print(f"   æˆåŠŸç‡: {success_rate:.1f}%")
                print(f"   å¹³å‡å®Œæˆæ—¶é—´: {avg_steps:.1f} ç§’")
                print(f"   è®­ç»ƒç”¨æ—¶: {elapsed_time:.1f} ç§’")
                print(f"   é¢„è®¡å‰©ä½™æ—¶é—´: {elapsed_time * (self.episodes - episode - 1) / (episode + 1):.1f} ç§’")
                progress_data = {
                    'episode': episode + 1,
                    'success_rate': success_rate,
                    'successful_episodes': successful_episodes,
                    'avg_steps': avg_steps,
                    'elapsed_time': elapsed_time
                }
                self.save_training_progress(progress_data)
        final_time = time.time() - start_time
        print(f"\nåƒå¸†å«æ˜Ÿè®­ç»ƒå®Œæˆï¼")
        print(f"   æœ€ç»ˆæˆåŠŸç‡: {successful_episodes/self.episodes*100:.1f}%")
        print(f"   æˆåŠŸä»»åŠ¡: {successful_episodes}/{self.episodes}")
        print(f"   æ€»è®­ç»ƒæ—¶é—´: {final_time:.1f} ç§’")
        print(f"   å¹³å‡å¯¹æ¥æ—¶é—´: {total_steps/self.episodes:.1f} ç§’")
        
        # ä½¿ç”¨é«˜è´¨é‡å¯è§†åŒ–è„šæœ¬å±•ç¤ºç»“æœ
        self.generate_professional_visualization()
    
    def generate_professional_visualization(self):
        """ä½¿ç”¨é«˜è´¨é‡ä¸“ä¸šå¯è§†åŒ–è„šæœ¬"""
        print("\næ­£åœ¨ç”Ÿæˆé¡¶åˆŠæ°´å‡†å¯è§†åŒ–åˆ†æ...")
        
        # æ‰§è¡Œä¸“ä¸šå¯è§†åŒ–è„šæœ¬
        visualization_script = os.path.join(
            os.path.dirname(os.path.dirname(os.path.abspath(__file__))), 
            'professional_visualization.py'
        )
        
        # åˆ›å»ºå¯è§†åŒ–è¾“å‡ºç›®å½•
        viz_output_dir = 'analysis_results'
        os.makedirs(viz_output_dir, exist_ok=True)
        
        # æ‰§è¡Œä¸“ä¸šå¯è§†åŒ–è„šæœ¬
        import subprocess
        cmd = f"cd {os.path.dirname(os.path.dirname(os.path.abspath(__file__)))} && python professional_visualization.py"
        
        print(f"æ‰§è¡Œé¡¶åˆŠæ°´å‡†ä¸“ä¸šå¯è§†åŒ–...")
        try:
            result = subprocess.run(cmd, shell=True, capture_output=True, text=True)
            if result.returncode == 0:
                print("âœ… ä¸“ä¸šå¯è§†åŒ–ç”ŸæˆæˆåŠŸï¼")
                print("ğŸ“Š æ£€æŸ¥ analysis_results/ ç›®å½•æŸ¥çœ‹é¡¶åˆŠæ°´å‡†å›¾è¡¨")
                print("   - professional_learning_curves.png")
                print("   - professional_performance_metrics.png") 
                print("   - professional_3d_trajectory.png")
                print("   - professional_dashboard.png")
            else:
                print(f"å¯è§†åŒ–æ‰§è¡Œé‡åˆ°é—®é¢˜: {result.stderr}")
        except Exception as e:
            print(f"å¯è§†åŒ–æ‰§è¡Œå¤±è´¥: {e}")

def main():
    """ä¸»å‡½æ•°"""
    print("åƒå¸†å«æ˜Ÿäº¤ä¼šå¯¹æ¥ä»»åŠ¡å¯åŠ¨")
    print("=" * 50)
    
    trainer = SimpleQianfanTrainer()
    trainer.train()
    print("\n" + "=" * 50)
    print("è®­ç»ƒä»»åŠ¡å®Œæˆï¼")

if __name__ == "__main__":
    main()